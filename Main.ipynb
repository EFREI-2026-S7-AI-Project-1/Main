{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# projet_cnn.py\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Utilise un backend compatible sans interface graphique\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "\n",
    "# Chargement et préparation des données\n",
    "def load_and_prepare_data():\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "    x_train = x_train.astype('float32') / 255.0\n",
    "    x_test = x_test.astype('float32') / 255.0\n",
    "    y_train_onehot = to_categorical(y_train, 10)\n",
    "    y_test_onehot = to_categorical(y_test, 10)\n",
    "    return (x_train, y_train), (x_test, y_test), y_train_onehot, y_test_onehot\n",
    "\n",
    "# Visualisation des images\n",
    "def plot_sample_images(x, y, class_names, num_images=5, filename='sample_images.png'):\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(1, num_images, i+1)\n",
    "        plt.imshow(x[i])\n",
    "        plt.title(class_names[int(y[i])])\n",
    "        plt.axis('off')\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "# Analyse de la distribution des classes\n",
    "def plot_class_distribution(y, class_names, filename='class_distribution.png'):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.hist(y, bins=np.arange(11) - 0.5, edgecolor='black', rwidth=0.8)\n",
    "    plt.xticks(np.arange(10), class_names, rotation=45)\n",
    "    plt.title('Distribution des classes dans l\\'ensemble d\\'entraînement')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "# Définition du modèle LeNet5\n",
    "def create_lenet5_model(input_shape=(32, 32, 3), num_classes=10):\n",
    "    model = Sequential([\n",
    "        Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(16, kernel_size=(5, 5), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(120, activation='relu'),\n",
    "        Dense(84, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def create_vgg_model(num_blocks, input_shape=(32, 32, 3), num_classes=10):\n",
    "    model = Sequential()\n",
    "    for i in range(num_blocks):\n",
    "        model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape if i == 0 else None))\n",
    "        model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def compile_and_train(model, x_train, y_train, x_test, y_test, optimizer, epochs=10):\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test), batch_size=64)\n",
    "    return history\n",
    "\n",
    "# Fonction pour tracer les courbes de performance\n",
    "def plot_history(history, title, filename):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "    plt.title(f'{title} - Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "    plt.title(f'{title} - Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Chargement des données\n",
    "    (x_train, y_train), (x_test, y_test), y_train_onehot, y_test_onehot = load_and_prepare_data()\n",
    "\n",
    "    # Affichage d'exemples d'images\n",
    "    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    plot_sample_images(x_train, y_train, class_names)\n",
    "\n",
    "    # Affichage de la distribution des classes\n",
    "    plot_class_distribution(y_train, class_names)\n",
    "\n",
    "    # Liste des optimiseurs à tester\n",
    "    optimizers = [\n",
    "        ('SGD', lambda: SGD(learning_rate=0.01, momentum=0.9)),\n",
    "        ('Adam', Adam),\n",
    "        ('RMSprop', RMSprop)\n",
    "    ]\n",
    "\n",
    "    # Définition des modèles\n",
    "    models = [\n",
    "        ('LeNet5', create_lenet5_model),\n",
    "        ('VGG1', lambda: create_vgg_model(num_blocks=1)),\n",
    "        ('VGG2', lambda: create_vgg_model(num_blocks=2)),\n",
    "        ('VGG3', lambda: create_vgg_model(num_blocks=3))\n",
    "    ]\n",
    "\n",
    "    # Entraînement et comparaison des modèles avec différents optimiseurs\n",
    "    for model_name, model_func in models:\n",
    "        for opt_name, optimizer_func in optimizers:\n",
    "            print(f\"Training {model_name} with {opt_name} optimizer...\")\n",
    "            model = model_func()  # Créer une nouvelle instance du modèle\n",
    "            optimizer = optimizer_func()  # Créer une nouvelle instance de l'optimiseur\n",
    "            history = compile_and_train(model, x_train, y_train_onehot, x_test, y_test_onehot, optimizer, epochs=10)\n",
    "            plot_history(history, f'{model_name} - {opt_name}', f'{model_name.lower()}_{opt_name.lower()}_history.png')\n",
    "\n",
    "    print(\"Training and evaluation completed. Check the generated plot files for results.\")\n",
    "\n",
    "# Exécution du script principal\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
