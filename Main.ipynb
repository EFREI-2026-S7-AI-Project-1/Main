{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14 15:28:42.357824: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-14 15:28:42.390527: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2369/1707299248.py:29: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  plt.title(class_names[int(y[i])])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LeNet5 with SGD optimizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.2574 - loss: 2.0104 - val_accuracy: 0.4346 - val_loss: 1.5641\n",
      "Epoch 2/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.4582 - loss: 1.5037 - val_accuracy: 0.4932 - val_loss: 1.4009\n",
      "Epoch 3/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5082 - loss: 1.3717 - val_accuracy: 0.5141 - val_loss: 1.3547\n",
      "Epoch 4/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5328 - loss: 1.3100 - val_accuracy: 0.5271 - val_loss: 1.3099\n",
      "Epoch 5/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5581 - loss: 1.2447 - val_accuracy: 0.5476 - val_loss: 1.2767\n",
      "Epoch 6/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.5789 - loss: 1.1877 - val_accuracy: 0.5600 - val_loss: 1.2547\n",
      "Epoch 7/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5947 - loss: 1.1465 - val_accuracy: 0.5452 - val_loss: 1.2705\n",
      "Epoch 8/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6112 - loss: 1.0980 - val_accuracy: 0.5758 - val_loss: 1.2241\n",
      "Epoch 9/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.6204 - loss: 1.0635 - val_accuracy: 0.5787 - val_loss: 1.2060\n",
      "Epoch 10/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.6368 - loss: 1.0177 - val_accuracy: 0.5645 - val_loss: 1.2411\n",
      "Training LeNet5 with Adam optimizer...\n",
      "Epoch 1/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.3277 - loss: 1.8348 - val_accuracy: 0.4318 - val_loss: 1.5579\n",
      "Epoch 2/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.4830 - loss: 1.4360 - val_accuracy: 0.5032 - val_loss: 1.3804\n",
      "Epoch 3/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5291 - loss: 1.3037 - val_accuracy: 0.5320 - val_loss: 1.2891\n",
      "Epoch 4/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5687 - loss: 1.2096 - val_accuracy: 0.5633 - val_loss: 1.2316\n",
      "Epoch 5/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5914 - loss: 1.1517 - val_accuracy: 0.5822 - val_loss: 1.1835\n",
      "Epoch 6/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6103 - loss: 1.1060 - val_accuracy: 0.5893 - val_loss: 1.1630\n",
      "Epoch 7/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6225 - loss: 1.0604 - val_accuracy: 0.5981 - val_loss: 1.1405\n",
      "Epoch 8/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6460 - loss: 1.0079 - val_accuracy: 0.5884 - val_loss: 1.2018\n",
      "Epoch 9/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6566 - loss: 0.9791 - val_accuracy: 0.6078 - val_loss: 1.1205\n",
      "Epoch 10/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6664 - loss: 0.9408 - val_accuracy: 0.6179 - val_loss: 1.1017\n",
      "Training LeNet5 with RMSprop optimizer...\n",
      "Epoch 1/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.2922 - loss: 1.9271 - val_accuracy: 0.4449 - val_loss: 1.5051\n",
      "Epoch 2/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4730 - loss: 1.4730 - val_accuracy: 0.5073 - val_loss: 1.3595\n",
      "Epoch 3/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5223 - loss: 1.3405 - val_accuracy: 0.5224 - val_loss: 1.3347\n",
      "Epoch 4/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5555 - loss: 1.2518 - val_accuracy: 0.4685 - val_loss: 1.4846\n",
      "Epoch 5/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5864 - loss: 1.1729 - val_accuracy: 0.5570 - val_loss: 1.2370\n",
      "Epoch 6/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.6054 - loss: 1.1121 - val_accuracy: 0.5134 - val_loss: 1.4356\n",
      "Epoch 7/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.6203 - loss: 1.0670 - val_accuracy: 0.5447 - val_loss: 1.3159\n",
      "Epoch 8/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.6396 - loss: 1.0159 - val_accuracy: 0.5881 - val_loss: 1.1701\n",
      "Epoch 9/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.6563 - loss: 0.9725 - val_accuracy: 0.5888 - val_loss: 1.1876\n",
      "Epoch 10/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.6720 - loss: 0.9356 - val_accuracy: 0.6009 - val_loss: 1.1524\n",
      "Training VGG1 with SGD optimizer...\n",
      "Epoch 1/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - accuracy: 0.2880 - loss: 1.9787 - val_accuracy: 0.4693 - val_loss: 1.4635\n",
      "Epoch 2/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.4768 - loss: 1.4444 - val_accuracy: 0.5549 - val_loss: 1.2512\n",
      "Epoch 3/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 20ms/step - accuracy: 0.5405 - loss: 1.2779 - val_accuracy: 0.6132 - val_loss: 1.0846\n",
      "Epoch 4/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.5824 - loss: 1.1771 - val_accuracy: 0.6447 - val_loss: 1.0113\n",
      "Epoch 5/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.6109 - loss: 1.0936 - val_accuracy: 0.6101 - val_loss: 1.0950\n",
      "Epoch 6/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.6316 - loss: 1.0404 - val_accuracy: 0.6438 - val_loss: 1.0035\n",
      "Epoch 7/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.6441 - loss: 1.0168 - val_accuracy: 0.6711 - val_loss: 0.9569\n",
      "Epoch 8/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.6561 - loss: 0.9810 - val_accuracy: 0.6588 - val_loss: 0.9711\n",
      "Epoch 9/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.6614 - loss: 0.9552 - val_accuracy: 0.6646 - val_loss: 0.9705\n",
      "Epoch 10/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 20ms/step - accuracy: 0.6709 - loss: 0.9277 - val_accuracy: 0.6655 - val_loss: 0.9726\n",
      "Training VGG1 with Adam optimizer...\n",
      "Epoch 1/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - accuracy: 0.3738 - loss: 1.7537 - val_accuracy: 0.5870 - val_loss: 1.1829\n",
      "Epoch 2/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - accuracy: 0.5745 - loss: 1.1962 - val_accuracy: 0.6256 - val_loss: 1.0802\n",
      "Epoch 3/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 21ms/step - accuracy: 0.6325 - loss: 1.0442 - val_accuracy: 0.6589 - val_loss: 0.9890\n",
      "Epoch 4/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 21ms/step - accuracy: 0.6600 - loss: 0.9578 - val_accuracy: 0.6655 - val_loss: 0.9575\n",
      "Epoch 5/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - accuracy: 0.6907 - loss: 0.8676 - val_accuracy: 0.6631 - val_loss: 0.9824\n",
      "Epoch 6/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - accuracy: 0.7089 - loss: 0.8271 - val_accuracy: 0.6437 - val_loss: 1.0683\n",
      "Epoch 7/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 21ms/step - accuracy: 0.7281 - loss: 0.7654 - val_accuracy: 0.6782 - val_loss: 0.9621\n",
      "Epoch 8/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 21ms/step - accuracy: 0.7406 - loss: 0.7293 - val_accuracy: 0.6904 - val_loss: 0.9030\n",
      "Epoch 9/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 21ms/step - accuracy: 0.7477 - loss: 0.7009 - val_accuracy: 0.6954 - val_loss: 0.9069\n",
      "Epoch 10/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - accuracy: 0.7605 - loss: 0.6718 - val_accuracy: 0.6992 - val_loss: 0.9210\n",
      "Training VGG1 with RMSprop optimizer...\n",
      "Epoch 1/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - accuracy: 0.3489 - loss: 1.8510 - val_accuracy: 0.4660 - val_loss: 1.6399\n",
      "Epoch 2/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.5361 - loss: 1.3295 - val_accuracy: 0.4427 - val_loss: 1.6419\n",
      "Epoch 3/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - accuracy: 0.5805 - loss: 1.2161 - val_accuracy: 0.5767 - val_loss: 2.0039\n",
      "Epoch 4/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - accuracy: 0.5952 - loss: 1.1772 - val_accuracy: 0.6013 - val_loss: 1.1718\n",
      "Epoch 5/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - accuracy: 0.6139 - loss: 1.1348 - val_accuracy: 0.6190 - val_loss: 1.2538\n",
      "Epoch 6/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - accuracy: 0.6140 - loss: 1.1373 - val_accuracy: 0.5715 - val_loss: 1.2533\n",
      "Epoch 7/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - accuracy: 0.6222 - loss: 1.1123 - val_accuracy: 0.5932 - val_loss: 1.2310\n",
      "Epoch 8/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.6276 - loss: 1.1028 - val_accuracy: 0.5701 - val_loss: 2.6194\n",
      "Epoch 9/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.6329 - loss: 1.0916 - val_accuracy: 0.6439 - val_loss: 1.4844\n",
      "Epoch 10/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.6390 - loss: 1.0738 - val_accuracy: 0.3876 - val_loss: 10.8879\n",
      "Training VGG2 with SGD optimizer...\n",
      "Epoch 1/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 30ms/step - accuracy: 0.2488 - loss: 2.0981 - val_accuracy: 0.4781 - val_loss: 1.4274\n",
      "Epoch 2/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 30ms/step - accuracy: 0.4499 - loss: 1.5099 - val_accuracy: 0.5292 - val_loss: 1.3015\n",
      "Epoch 3/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 30ms/step - accuracy: 0.5278 - loss: 1.3076 - val_accuracy: 0.5978 - val_loss: 1.1425\n",
      "Epoch 4/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 30ms/step - accuracy: 0.5695 - loss: 1.1959 - val_accuracy: 0.6340 - val_loss: 1.0545\n",
      "Epoch 5/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 29ms/step - accuracy: 0.6013 - loss: 1.1173 - val_accuracy: 0.6663 - val_loss: 0.9347\n",
      "Epoch 6/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 29ms/step - accuracy: 0.6309 - loss: 1.0427 - val_accuracy: 0.6375 - val_loss: 1.0148\n",
      "Epoch 7/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.6532 - loss: 0.9865 - val_accuracy: 0.6502 - val_loss: 0.9860\n",
      "Epoch 8/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 29ms/step - accuracy: 0.6647 - loss: 0.9511 - val_accuracy: 0.6913 - val_loss: 0.8838\n",
      "Epoch 9/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 30ms/step - accuracy: 0.6765 - loss: 0.9184 - val_accuracy: 0.7065 - val_loss: 0.8440\n",
      "Epoch 10/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.6823 - loss: 0.8945 - val_accuracy: 0.7095 - val_loss: 0.8362\n",
      "Training VGG2 with Adam optimizer...\n",
      "Epoch 1/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 32ms/step - accuracy: 0.2933 - loss: 1.9965 - val_accuracy: 0.4591 - val_loss: 1.5797\n",
      "Epoch 2/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 30ms/step - accuracy: 0.4887 - loss: 1.4176 - val_accuracy: 0.6026 - val_loss: 1.1257\n",
      "Epoch 3/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 29ms/step - accuracy: 0.5722 - loss: 1.2095 - val_accuracy: 0.6607 - val_loss: 0.9548\n",
      "Epoch 4/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 28ms/step - accuracy: 0.6220 - loss: 1.0669 - val_accuracy: 0.6447 - val_loss: 1.0319\n",
      "Epoch 5/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 27ms/step - accuracy: 0.6646 - loss: 0.9508 - val_accuracy: 0.7053 - val_loss: 0.8252\n",
      "Epoch 6/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 28ms/step - accuracy: 0.6846 - loss: 0.9017 - val_accuracy: 0.7109 - val_loss: 0.8165\n",
      "Epoch 7/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 29ms/step - accuracy: 0.7012 - loss: 0.8523 - val_accuracy: 0.7414 - val_loss: 0.7492\n",
      "Epoch 8/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 29ms/step - accuracy: 0.7152 - loss: 0.8081 - val_accuracy: 0.7157 - val_loss: 0.7979\n",
      "Epoch 9/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 29ms/step - accuracy: 0.7244 - loss: 0.7846 - val_accuracy: 0.7465 - val_loss: 0.7224\n",
      "Epoch 10/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 29ms/step - accuracy: 0.7355 - loss: 0.7570 - val_accuracy: 0.7251 - val_loss: 0.8046\n",
      "Training VGG2 with RMSprop optimizer...\n",
      "Epoch 1/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 29ms/step - accuracy: 0.2990 - loss: 2.0044 - val_accuracy: 0.3734 - val_loss: 1.7871\n",
      "Epoch 2/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 30ms/step - accuracy: 0.4980 - loss: 1.4213 - val_accuracy: 0.5208 - val_loss: 1.4573\n",
      "Epoch 3/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 28ms/step - accuracy: 0.5625 - loss: 1.2489 - val_accuracy: 0.6537 - val_loss: 1.0278\n",
      "Epoch 4/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 29ms/step - accuracy: 0.6131 - loss: 1.1390 - val_accuracy: 0.6205 - val_loss: 1.1079\n",
      "Epoch 5/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 29ms/step - accuracy: 0.6347 - loss: 1.0685 - val_accuracy: 0.6501 - val_loss: 1.2132\n",
      "Epoch 6/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 29ms/step - accuracy: 0.6482 - loss: 1.0350 - val_accuracy: 0.6633 - val_loss: 1.0403\n",
      "Epoch 7/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 30ms/step - accuracy: 0.6575 - loss: 1.0024 - val_accuracy: 0.6926 - val_loss: 0.8971\n",
      "Epoch 8/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.6707 - loss: 0.9723 - val_accuracy: 0.7075 - val_loss: 0.9518\n",
      "Epoch 9/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 30ms/step - accuracy: 0.6843 - loss: 0.9352 - val_accuracy: 0.7012 - val_loss: 0.9197\n",
      "Epoch 10/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 29ms/step - accuracy: 0.6922 - loss: 0.9094 - val_accuracy: 0.7096 - val_loss: 0.8840\n",
      "Training VGG3 with SGD optimizer...\n",
      "Epoch 1/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 34ms/step - accuracy: 0.2292 - loss: 2.1758 - val_accuracy: 0.3359 - val_loss: 1.8102\n",
      "Epoch 2/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 32ms/step - accuracy: 0.3918 - loss: 1.6421 - val_accuracy: 0.4495 - val_loss: 1.4684\n",
      "Epoch 3/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 33ms/step - accuracy: 0.4639 - loss: 1.4598 - val_accuracy: 0.5593 - val_loss: 1.2107\n",
      "Epoch 4/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 33ms/step - accuracy: 0.5191 - loss: 1.3206 - val_accuracy: 0.5104 - val_loss: 1.4206\n",
      "Epoch 5/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 37ms/step - accuracy: 0.5626 - loss: 1.2207 - val_accuracy: 0.5207 - val_loss: 1.4161\n",
      "Epoch 6/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 36ms/step - accuracy: 0.5938 - loss: 1.1427 - val_accuracy: 0.6132 - val_loss: 1.0914\n",
      "Epoch 7/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 35ms/step - accuracy: 0.6127 - loss: 1.0948 - val_accuracy: 0.6508 - val_loss: 1.0076\n",
      "Epoch 8/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 34ms/step - accuracy: 0.6343 - loss: 1.0350 - val_accuracy: 0.6879 - val_loss: 0.8948\n",
      "Epoch 9/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 34ms/step - accuracy: 0.6485 - loss: 0.9863 - val_accuracy: 0.7034 - val_loss: 0.8337\n",
      "Epoch 10/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 34ms/step - accuracy: 0.6659 - loss: 0.9534 - val_accuracy: 0.6886 - val_loss: 0.8681\n",
      "Training VGG3 with Adam optimizer...\n",
      "Epoch 1/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 34ms/step - accuracy: 0.2576 - loss: 2.1235 - val_accuracy: 0.4109 - val_loss: 1.7905\n",
      "Epoch 2/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 34ms/step - accuracy: 0.4569 - loss: 1.4798 - val_accuracy: 0.4675 - val_loss: 1.4633\n",
      "Epoch 3/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 33ms/step - accuracy: 0.5480 - loss: 1.2585 - val_accuracy: 0.6292 - val_loss: 1.0454\n",
      "Epoch 4/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 32ms/step - accuracy: 0.6113 - loss: 1.1027 - val_accuracy: 0.6262 - val_loss: 1.0459\n",
      "Epoch 5/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.6451 - loss: 1.0081 - val_accuracy: 0.6524 - val_loss: 0.9937\n",
      "Epoch 6/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 32ms/step - accuracy: 0.6632 - loss: 0.9512 - val_accuracy: 0.6920 - val_loss: 0.8712\n",
      "Epoch 7/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 33ms/step - accuracy: 0.6889 - loss: 0.8939 - val_accuracy: 0.6897 - val_loss: 0.8745\n",
      "Epoch 8/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.6923 - loss: 0.8753 - val_accuracy: 0.7182 - val_loss: 0.8018\n",
      "Epoch 9/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 35ms/step - accuracy: 0.7075 - loss: 0.8411 - val_accuracy: 0.7229 - val_loss: 0.8078\n",
      "Epoch 10/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.7106 - loss: 0.8172 - val_accuracy: 0.7582 - val_loss: 0.7009\n",
      "Training VGG3 with RMSprop optimizer...\n",
      "Epoch 1/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 36ms/step - accuracy: 0.2684 - loss: 2.0814 - val_accuracy: 0.4142 - val_loss: 1.6530\n",
      "Epoch 2/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.4812 - loss: 1.4337 - val_accuracy: 0.4934 - val_loss: 1.5031\n",
      "Epoch 3/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 35ms/step - accuracy: 0.5551 - loss: 1.2599 - val_accuracy: 0.6040 - val_loss: 1.0858\n",
      "Epoch 4/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 34ms/step - accuracy: 0.5932 - loss: 1.1535 - val_accuracy: 0.5450 - val_loss: 1.3555\n",
      "Epoch 5/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.6239 - loss: 1.0816 - val_accuracy: 0.6592 - val_loss: 0.9606\n",
      "Epoch 6/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.6393 - loss: 1.0393 - val_accuracy: 0.6155 - val_loss: 1.2052\n",
      "Epoch 7/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 32ms/step - accuracy: 0.6524 - loss: 1.0012 - val_accuracy: 0.5516 - val_loss: 1.4636\n",
      "Epoch 8/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 30ms/step - accuracy: 0.6662 - loss: 0.9563 - val_accuracy: 0.6649 - val_loss: 0.9971\n",
      "Epoch 9/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.6788 - loss: 0.9291 - val_accuracy: 0.6668 - val_loss: 1.0746\n",
      "Epoch 10/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 30ms/step - accuracy: 0.6906 - loss: 0.8948 - val_accuracy: 0.6865 - val_loss: 0.8881\n",
      "Training and evaluation completed. Check the generated plot files for results.\n"
     ]
    }
   ],
   "source": [
    "# projet_cnn.py\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use(\"Agg\")  # Utilise un backend compatible sans interface graphique\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    BatchNormalization,\n",
    ")\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "\n",
    "\n",
    "# Chargement et préparation des données\n",
    "def load_and_prepare_data():\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "    x_train = x_train.astype(\"float32\") / 255.0\n",
    "    x_test = x_test.astype(\"float32\") / 255.0\n",
    "    y_train_onehot = to_categorical(y_train, 10)\n",
    "    y_test_onehot = to_categorical(y_test, 10)\n",
    "    return (x_train, y_train), (x_test, y_test), y_train_onehot, y_test_onehot\n",
    "\n",
    "\n",
    "# Visualisation des images\n",
    "def plot_sample_images(x, y, class_names, num_images=5, filename=\"sample_images.png\"):\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(1, num_images, i + 1)\n",
    "        plt.imshow(x[i])\n",
    "        plt.title(class_names[int(y[i])])\n",
    "        plt.axis(\"off\")\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# Analyse de la distribution des classes\n",
    "def plot_class_distribution(y, class_names, filename=\"class_distribution.png\"):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.hist(y, bins=np.arange(11) - 0.5, edgecolor=\"black\", rwidth=0.8)\n",
    "    plt.xticks(np.arange(10), class_names, rotation=45)\n",
    "    plt.title(\"Distribution des classes dans l'ensemble d'entraînement\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# Définition du modèle LeNet5\n",
    "def create_lenet5_model(input_shape=(32, 32, 3), num_classes=10):\n",
    "    model = Sequential(\n",
    "        [\n",
    "            Conv2D(6, kernel_size=(5, 5), activation=\"relu\", input_shape=input_shape),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "            Conv2D(16, kernel_size=(5, 5), activation=\"relu\"),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "            Flatten(),\n",
    "            Dense(120, activation=\"relu\"),\n",
    "            Dense(84, activation=\"relu\"),\n",
    "            Dense(num_classes, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_vgg_model(num_blocks, input_shape=(32, 32, 3), num_classes=10):\n",
    "    model = Sequential()\n",
    "    for i in range(num_blocks):\n",
    "        model.add(\n",
    "            Conv2D(\n",
    "                32,\n",
    "                (3, 3),\n",
    "                padding=\"same\",\n",
    "                activation=\"relu\",\n",
    "                input_shape=input_shape if i == 0 else None,\n",
    "            )\n",
    "        )\n",
    "        model.add(Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "    return model\n",
    "\n",
    "\n",
    "def compile_and_train(model, x_train, y_train, x_test, y_test, optimizer, epochs=10):\n",
    "    model.compile(\n",
    "        optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    history = model.fit(\n",
    "        x_train, y_train, epochs=epochs, validation_data=(x_test, y_test), batch_size=64\n",
    "    )\n",
    "    return history\n",
    "\n",
    "\n",
    "# Fonction pour tracer les courbes de performance\n",
    "def plot_history(history, title, filename):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "    plt.plot(history.history[\"val_loss\"], label=\"Val Loss\")\n",
    "    plt.title(f\"{title} - Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n",
    "    plt.plot(history.history[\"val_accuracy\"], label=\"Val Accuracy\")\n",
    "    plt.title(f\"{title} - Accuracy\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Chargement des données\n",
    "    (x_train, y_train), (x_test, y_test), y_train_onehot, y_test_onehot = (\n",
    "        load_and_prepare_data()\n",
    "    )\n",
    "\n",
    "    # Affichage d'exemples d'images\n",
    "    class_names = [\n",
    "        \"airplane\",\n",
    "        \"automobile\",\n",
    "        \"bird\",\n",
    "        \"cat\",\n",
    "        \"deer\",\n",
    "        \"dog\",\n",
    "        \"frog\",\n",
    "        \"horse\",\n",
    "        \"ship\",\n",
    "        \"truck\",\n",
    "    ]\n",
    "    plot_sample_images(x_train, y_train, class_names)\n",
    "\n",
    "    # Affichage de la distribution des classes\n",
    "    plot_class_distribution(y_train, class_names)\n",
    "\n",
    "    # Liste des optimiseurs à tester\n",
    "    optimizers = [\n",
    "        (\"SGD\", lambda: SGD(learning_rate=0.01, momentum=0.9)),\n",
    "        (\"Adam\", Adam),\n",
    "        (\"RMSprop\", RMSprop),\n",
    "    ]\n",
    "\n",
    "    # Définition des modèles\n",
    "    models = [\n",
    "        (\"LeNet5\", create_lenet5_model),\n",
    "        (\"VGG1\", lambda: create_vgg_model(num_blocks=1)),\n",
    "        (\"VGG2\", lambda: create_vgg_model(num_blocks=2)),\n",
    "        (\"VGG3\", lambda: create_vgg_model(num_blocks=3)),\n",
    "    ]\n",
    "\n",
    "    # Entraînement et comparaison des modèles avec différents optimiseurs\n",
    "    for model_name, model_func in models:\n",
    "        for opt_name, optimizer_func in optimizers:\n",
    "            print(f\"Training {model_name} with {opt_name} optimizer...\")\n",
    "            model = model_func()  # Créer une nouvelle instance du modèle\n",
    "            optimizer = optimizer_func()  # Créer une nouvelle instance de l'optimiseur\n",
    "            history = compile_and_train(\n",
    "                model,\n",
    "                x_train,\n",
    "                y_train_onehot,\n",
    "                x_test,\n",
    "                y_test_onehot,\n",
    "                optimizer,\n",
    "                epochs=10,\n",
    "            )\n",
    "            plot_history(\n",
    "                history,\n",
    "                f\"{model_name} - {opt_name}\",\n",
    "                f\"{model_name.lower()}_{opt_name.lower()}_history.png\",\n",
    "            )\n",
    "\n",
    "    print(\n",
    "        \"Training and evaluation completed. Check the generated plot files for results.\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Exécution du script principal\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
